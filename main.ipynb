{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">C:\\Users\\Kariem\\AppData\\Local\\Temp\\ipykernel_25528\\</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3665443383.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">6</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: The `airflow.operators.email_operator.EmailOperator` class is deprecated. Please use `</span><span style=\"color: #808000; text-decoration-color: #808000\">'airflow.operators.email.EmailOperator'</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mC:\\Users\\Kariem\\AppData\\Local\\Temp\\ipykernel_25528\\\u001b[0m\u001b[1;33m3665443383.\u001b[0m\u001b[1;33mpy:\u001b[0m\u001b[1;33m6\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: The `airflow.operators.email_operator.EmailOperator` class is deprecated. Please use `\u001b[0m\u001b[33m'airflow.operators.email.EmailOperator'\u001b[0m\u001b[33m`.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from airflow import DAG\n",
    "from datetime import datetime\n",
    "from airflow.operators.python import PythonOperator, BranchPythonOperator\n",
    "from airflow.operators.email_operator import EmailOperator\n",
    "from airflow.utils.dates import days_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the transactional PostgreSQL database\n",
    "conn_transactional = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5433\",\n",
    "    database=\"transactional_db\",\n",
    "    user=\"user\",\n",
    "    password=\"password\"\n",
    ")\n",
    "\n",
    "# Connect to the data warehouse PostgreSQL database\n",
    "conn_dwh = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5434\",\n",
    "    database=\"dwh_db\",\n",
    "    user=\"user\",\n",
    "    password=\"password\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to both transactional and DWH databases successfully!\n"
     ]
    }
   ],
   "source": [
    "cur_transactional = conn_transactional.cursor()\n",
    "cur_dwh = conn_dwh.cursor()\n",
    "\n",
    "# Print a success message as test\n",
    "print(\"Connected to both transactional and DWH databases successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL queries to create tables\n",
    "create_users_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    user_id SERIAL PRIMARY KEY,\n",
    "    user_name VARCHAR(50),\n",
    "    email VARCHAR(50) UNIQUE,\n",
    "    wallet_balance NUMERIC(10, 2),\n",
    "    phone_number VARCHAR(20),\n",
    "    address VARCHAR(100)\n",
    ");\n",
    "\"\"\"\n",
    "create_author_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS authors (\n",
    "    author_id SERIAL PRIMARY KEY,\n",
    "    author_name VARCHAR(50),\n",
    "    email VARCHAR(50) UNIQUE,\n",
    "    nationality VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "create_book_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS books (\n",
    "    book_id SERIAL PRIMARY KEY,\n",
    "    title VARCHAR(100),\n",
    "    publish_date DATE,\n",
    "    isbn VARCHAR(20),\n",
    "    genre VARCHAR(50),\n",
    "    price NUMERIC(10, 2)\n",
    ");\n",
    "\"\"\"\n",
    "create_book_author_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS book_author (\n",
    "    book_id INT,\n",
    "    author_id INT,\n",
    "    CONSTRAINT fk_book_id FOREIGN KEY (book_id) REFERENCES books(book_id),\n",
    "    CONSTRAINT fk_author_id FOREIGN KEY (author_id) REFERENCES authors(author_id),\n",
    "    PRIMARY KEY (book_id, author_id)\n",
    ");\n",
    "\"\"\"\n",
    "create_review_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS reviews (\n",
    "    review_id SERIAL PRIMARY KEY,\n",
    "    user_id INT,\n",
    "    book_id INT,\n",
    "    rate INT CHECK (rate >= 1 AND rate <= 5),\n",
    "    review_text TEXT,\n",
    "    review_date DATE,\n",
    "    FOREIGN KEY (user_id) REFERENCES users(user_id),\n",
    "    FOREIGN KEY (book_id) REFERENCES books(book_id)\n",
    ");\n",
    "\"\"\"\n",
    "create_order_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS orders (\n",
    "    order_id SERIAL PRIMARY KEY,\n",
    "    user_id INT,\n",
    "    order_date DATE,\n",
    "    total_amount NUMERIC(10, 2),\n",
    "    order_created DATE,\n",
    "    order_completed DATE,\n",
    "    FOREIGN KEY (user_id) REFERENCES users(user_id)\n",
    ");\n",
    "\"\"\"\n",
    "create_order_book_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS order_book (\n",
    "    order_id INT,\n",
    "    book_id INT,\n",
    "    quantity INT,\n",
    "    PRIMARY KEY (order_id, book_id),\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
    "    FOREIGN KEY (book_id) REFERENCES books(book_id)\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the table creation queries on the transacional database\n",
    "cur_transactional.execute(create_users_table)\n",
    "cur_transactional.execute(create_book_table)\n",
    "cur_transactional.execute(create_author_table)\n",
    "cur_transactional.execute(create_book_author_table)\n",
    "cur_transactional.execute(create_review_table)\n",
    "cur_transactional.execute(create_order_table)\n",
    "cur_transactional.execute(create_order_book_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_transactional.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star schema tables created successfully in the DWH database!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # SQL statements to create the star schema tables\n",
    "    create_dim_user = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_user (\n",
    "        user_id SERIAL PRIMARY KEY,\n",
    "        user_name VARCHAR(100),\n",
    "        email VARCHAR(100) UNIQUE,\n",
    "        phone_number VARCHAR(20),\n",
    "        address VARCHAR(255)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_dim_author = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_author (\n",
    "        author_id SERIAL PRIMARY KEY,\n",
    "        author_name VARCHAR(100),\n",
    "        nationality VARCHAR(50)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_dim_book = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_book (\n",
    "        book_id SERIAL PRIMARY KEY,\n",
    "        title VARCHAR(255),\n",
    "        author_id INT,\n",
    "        genre VARCHAR(50),\n",
    "        price NUMERIC(10, 2),\n",
    "        publish_date DATE,\n",
    "        FOREIGN KEY (author_id) REFERENCES dim_author(author_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_dim_time = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_time (\n",
    "        time_id SERIAL PRIMARY KEY,\n",
    "        date DATE,\n",
    "        year INT,\n",
    "        month INT,\n",
    "        day INT,\n",
    "        quarter INT\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_fact_sales = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fact_sales (\n",
    "        sales_id SERIAL PRIMARY KEY,\n",
    "        book_id INT,\n",
    "        user_id INT,\n",
    "        time_id INT,\n",
    "        quantity_sold INT,\n",
    "        total_amount NUMERIC(10, 2),\n",
    "        FOREIGN KEY (book_id) REFERENCES dim_book(book_id),\n",
    "        FOREIGN KEY (user_id) REFERENCES dim_user(user_id),\n",
    "        FOREIGN KEY (time_id) REFERENCES dim_time(time_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the table creation queries for the star schema\n",
    "    cur_dwh.execute(create_dim_user)\n",
    "    cur_dwh.execute(create_dim_author)\n",
    "    cur_dwh.execute(create_dim_book)\n",
    "    cur_dwh.execute(create_dim_time)\n",
    "    cur_dwh.execute(create_fact_sales)\n",
    "\n",
    "    # Commit the changes\n",
    "    conn_dwh.commit()\n",
    "    print(\"Star schema tables created successfully in the DWH database!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    conn_dwh.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alter and edit some columns to fit the data\n",
    "cur_transactional.execute(\"ALTER TABLE authors ALTER COLUMN author_name TYPE VARCHAR(100);\")\n",
    "cur_transactional.execute(\"ALTER TABLE users ALTER COLUMN user_name TYPE VARCHAR(100);\")\n",
    "cur_transactional.execute(\"ALTER TABLE authors ALTER COLUMN email TYPE VARCHAR(100);\")\n",
    "cur_transactional.execute(\"ALTER TABLE books ALTER COLUMN genre TYPE VARCHAR(100);\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "DATABASE_TYPE = 'postgresql'  \n",
    "DBAPI = 'psycopg2'  \n",
    "USER = 'user'\n",
    "PASSWORD = 'password'\n",
    "HOST = 'localhost'  \n",
    "PORT = '5433'  \n",
    "DATABASE = 'transactional_db'\n",
    "\n",
    "# Create a database URI\n",
    "db_uri = f\"{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "DATABASE_TYPE = 'postgresql'  \n",
    "DBAPI = 'psycopg2'  \n",
    "USER = 'user'\n",
    "PASSWORD = 'password'\n",
    "HOST = 'localhost'  \n",
    "PORT = '5434'  \n",
    "DATABASE = 'dwh_db'\n",
    "\n",
    "# Create a database URI\n",
    "db_uri = f\"{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine_dwh= create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_TYPE = 'postgresql'  \n",
    "DBAPI = 'psycopg2'  \n",
    "USER = 'user'\n",
    "PASSWORD = 'password'\n",
    "HOST = 'localhost'  \n",
    "PORT = '5433'  \n",
    "DATABASE = 'transactional_db'\n",
    "\n",
    "# Create a database URI\n",
    "db_uri = f\"{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine_tr= create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "Could not parse SQLAlchemy URL from string 'your_database_url'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine\n\u001b[1;32m----> 4\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myour_database_url\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Define your database URL here\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DAG(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETL_DAG\u001b[39m\u001b[38;5;124m\"\u001b[39m, start_date\u001b[38;5;241m=\u001b[39mdatetime(\u001b[38;5;241m2021\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), schedule_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@daily\u001b[39m\u001b[38;5;124m\"\u001b[39m, catchup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m dag:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract\u001b[39m():\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# Extract data from the transactional database\u001b[39;00m\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\util\\deprecations.py:375\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    369\u001b[0m         _warn_with_version(\n\u001b[0;32m    370\u001b[0m             messages[m],\n\u001b[0;32m    371\u001b[0m             versions[m],\n\u001b[0;32m    372\u001b[0m             version_warnings[m],\n\u001b[0;32m    373\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    374\u001b[0m         )\n\u001b[1;32m--> 375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\create.py:514\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty_in_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# create url.URL object\u001b[39;00m\n\u001b[1;32m--> 514\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43m_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m u, plugins, kwargs \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_instantiate_plugins(kwargs)\n\u001b[0;32m    518\u001b[0m entrypoint \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_get_entrypoint()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\url.py:738\u001b[0m, in \u001b[0;36mmake_url\u001b[1;34m(name_or_url)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given a string or unicode instance, produce a new URL instance.\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \n\u001b[0;32m    727\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m \n\u001b[0;32m    735\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_url, util\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[1;32m--> 738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name_or_url\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\url.py:799\u001b[0m, in \u001b[0;36m_parse_url\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m URL\u001b[38;5;241m.\u001b[39mcreate(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponents)\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mArgumentError(\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse SQLAlchemy URL from string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name\n\u001b[0;32m    801\u001b[0m     )\n",
      "\u001b[1;31mArgumentError\u001b[0m: Could not parse SQLAlchemy URL from string 'your_database_url'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "with DAG(\"ETL_DAG\", start_date=datetime(2021, 1, 1), schedule_interval=\"@daily\", catchup=False) as dag:\n",
    "    \n",
    "    def extract():\n",
    "        # Extract data from the transactional database\n",
    "        users_query = \"SELECT * FROM users;\"\n",
    "        authors_query = \"SELECT * FROM authors;\"\n",
    "        books_query = \"SELECT * FROM books;\"\n",
    "        reviews_query = \"SELECT * FROM reviews;\"\n",
    "        orders_query = \"SELECT * FROM orders;\"\n",
    "        order_book_query = \"SELECT * FROM order_book;\"\n",
    "\n",
    "        users_df = pd.read_sql(users_query, engine_tr)\n",
    "        authors_df = pd.read_sql(authors_query, engine_tr)\n",
    "        books_df = pd.read_sql(books_query, engine_tr)\n",
    "        reviews_df = pd.read_sql(reviews_query, engine_tr)\n",
    "        orders_df = pd.read_sql(orders_query, engine_tr)\n",
    "        order_book_df = pd.read_sql(order_book_query, engine_tr)\n",
    "\n",
    "        return users_df, authors_df, books_df, reviews_df, orders_df, order_book_df\n",
    "\n",
    "    def transform(users_df, authors_df, books_df, reviews_df, orders_df, order_book_df):\n",
    "        # Transform the data\n",
    "        users_df = users_df.rename(columns={\"user_id\": \"user_id\", \"user_name\": \"user_name\", \"email\": \"email\", \n",
    "                                             \"wallet_balance\": \"wallet_balance\", \"phone_number\": \"phone_number\", \n",
    "                                             \"address\": \"address\"})\n",
    "        authors_df = authors_df.rename(columns={\"author_id\": \"author_id\", \"author_name\": \"author_name\", \n",
    "                                                 \"email\": \"email\", \"national\": \"national\"})\n",
    "        books_df = books_df.rename(columns={\"book_id\": \"book_id\", \"title\": \"title\", \"publish_date\": \"publish_date\", \n",
    "                                             \"isbn\": \"isbn\", \"genre\": \"genre\", \"price\": \"price\"})\n",
    "        reviews_df = reviews_df.rename(columns={\"review_id\": \"review_id\", \"user_id\": \"user_id\", \n",
    "                                                 \"book_id\": \"book_id\", \"rate\": \"rate\", \n",
    "                                                 \"review_text\": \"review_text\", \"review_date\": \"review_date\"})\n",
    "        orders_df = orders_df.rename(columns={\"order_id\": \"order_id\", \"user_id\": \"user_id\", \n",
    "                                               \"order_date\": \"order_date\", \"total_amount\": \"total_amount\", \n",
    "                                               \"order_created\": \"order_created\", \"order_completed\": \"order_completed\"})\n",
    "        order_book_df = order_book_df.rename(columns={\"order_id\": \"order_id\", \"book_id\": \"book_id\", \n",
    "                                                       \"quantity\": \"quantity\"})\n",
    "\n",
    "        return users_df, authors_df, books_df, reviews_df, orders_df, order_book_df\n",
    "\n",
    "    def load(users_df, authors_df, books_df, reviews_df, orders_df, order_book_df):\n",
    "        # Load the data into the data warehouse\n",
    "        users_df.to_sql(\"users\", engine_dwh, if_exists=\"replace\", index=False)\n",
    "        authors_df.to_sql(\"authors\", engine_dwh, if_exists=\"replace\", index=False)\n",
    "        books_df.to_sql(\"books\", engine_dwh, if_exists=\"replace\", index=False)\n",
    "        reviews_df.to_sql(\"reviews\", engine_dwh, if_exists=\"replace\", index=False)\n",
    "        orders_df.to_sql(\"orders\", engine_dwh, if_exists=\"replace\", index=False)\n",
    "        order_book_df.to_sql(\"order_book\", engine_dwh, if_exists=\"replace\", index=False)\n",
    "\n",
    "    # Define tasks\n",
    "    extract_phase = PythonOperator(\n",
    "        task_id=\"extract_phase\",\n",
    "        python_callable=extract,\n",
    "        provide_context=True,\n",
    "    )\n",
    "\n",
    "    transform_phase = PythonOperator(\n",
    "        task_id=\"transform_phase\",\n",
    "        python_callable=transform,\n",
    "        op_args=[\"{{ task_instance.xcom_pull(task_ids='extract_phase') }}\"],\n",
    "        provide_context=True,\n",
    "    )\n",
    "\n",
    "    load_phase = PythonOperator(\n",
    "        task_id=\"load_phase\",\n",
    "        python_callable=load,\n",
    "        op_args=[\"{{ task_instance.xcom_pull(task_ids='transform_phase') }}\"],\n",
    "        provide_context=True,\n",
    "    )\n",
    "\n",
    "    email_status = EmailOperator(\n",
    "        task_id='email_on_success',\n",
    "        to='Kariemg05@gmail.com',\n",
    "        subject='Pipeline Success',\n",
    "        html_content='The pipeline has completed successfully.',\n",
    "    )\n",
    "\n",
    "    # Set task dependencies\n",
    "    extract_phase >> transform_phase >> load_phase >> email_status\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
